Welcome to the AI Mock Interviewer!

The provided code defines a sophisticated AI mock interviewer using a combination of Gradio, Speech Recognition, Google Text-to-Speech (gTTS), and the Hugging Face Inference API. This model is designed to simulate a realistic interview environment, allowing users to practice and improve their interview skills. 

=>Key Features of the Code:

1. API Integration with Hugging Face
      - Utilizes InferenceClient from the Hugging Face Hub to access a pre-trained model (meta-llama/Meta-Llama-3-8B-Instruct).
      - Handles chat completions for generating interview questions, verifying answers, providing hints, and generating feedback.

2. Speech Recognition and Synthesis
      - Speech Recognition: Uses the speech_recognition library to transcribe user's spoken answers from audio files.
      - Speech Synthesis: Utilizes the gTTS library to convert text to speech, enhancing user interaction through auditory feedback.
      -  Audio Playback: Uses IPython's Audio module to play the generated audio files.

3. Interview Simulation
      - Welcome and User Interaction: Plays a welcome message, collects the user's name, topic, position, and difficulty level through both audio prompts and text inputs.
      - Question Generation: Generates interview questions based on the provided topic, position, and difficulty, ensuring no repetition.
      - Answer Verification: Verifies the user's spoken answers against generated questions and provides feedback.
      - Hint Generation: Provides hints for incorrect answers to assist the user.
      - Correct Answer Provision: Supplies the correct answer if the user fails to answer correctly even after a hint.
      - Feedback Generation: Generates detailed feedback based on the user's performance, emphasizing strengths and areas for improvement.

4. Gradio Interface
       Modular Components:
             - Textbox: For displaying questions and interviewer's responses.
             - Audio Input: For uploading and processing user's spoken answers.
             - Buttons: For transcribing and submitting answers.
       Interactive Workflow:
             - Real-time Transcription: Converts uploaded audio answers to text.
             - Dynamic Question Handling: Updates and displays new questions based on user interactions.

5. User Experience Enhancements
      - Speech Prompts: Guides the user through the interview process with spoken prompts.
      - Sequential Question Handling: Ensures a smooth flow of interview questions and answers.
      - Completion Handling: Allows the user to finish the interview and receive comprehensive feedback on their performance.

6. Modular Functions
      - get_system_prompt: Generates a system prompt based on the topic.
      - generate_question: Creates relevant and non-repetitive questions.
      - verify_answer: Verifies the correctness of the user's answer.
      - generate_hint: Provides hints for difficult questions.
      - get_correct_answer: Retrieves the correct answer for a given question.
      - speak: Converts text to speech.
      - play_audio: Plays the generated audio files.
      - recognize_speech: Converts speech from an audio file to text.
      - generate_feedback: Provides detailed feedback based on the conversation history.
      - conduct_interview: Manages the interview process, generating questions and handling answers.
